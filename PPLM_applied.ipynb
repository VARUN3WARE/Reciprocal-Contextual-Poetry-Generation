{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch numpy -q\n",
        "#setup\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import numpy as np\n",
        "from typing import List\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úì Packages installed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyrF6kL_C0dI",
        "outputId": "fb04c44f-cb27-4781-f40e-9b714110ccf7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Packages installed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Model for Poetry\n",
        "\n",
        "print(\"Loading GPT-2 Medium for Poetry Generation...\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "model_name = 'gpt2-medium'\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "print(\"‚úì Model loaded!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4Of8VzrC7Uz",
        "outputId": "f0f7658e-9da7-4f92-afe3-e089c53001c1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading GPT-2 Medium for Poetry Generation...\n",
            "Device: cpu\n",
            "‚úì Model loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#POETIC THEMES & VOCABULARIES\n",
        "\n",
        "\n",
        "print(\"Defining Poetic Themes...\")\n",
        "\n",
        "# Rich poetic vocabularies for different themes\n",
        "POETRY_THEMES = {\n",
        "    'love': [\n",
        "        'love', 'heart', 'soul', 'passion', 'desire', 'kiss', 'embrace',\n",
        "        'tender', 'gentle', 'sweet', 'beautiful', 'beloved', 'darling',\n",
        "        'cherish', 'adore', 'devotion', 'affection', 'romance', 'intimate',\n",
        "        'longing', 'yearning', 'forever', 'eternal', 'together', 'unite',\n",
        "        'bond', 'connection', 'warmth', 'caring', 'treasure', 'precious'\n",
        "    ],\n",
        "\n",
        "    'nature': [\n",
        "        'sky', 'earth', 'moon', 'stars', 'sun', 'wind', 'rain', 'clouds',\n",
        "        'mountains', 'ocean', 'sea', 'waves', 'forest', 'trees', 'flowers',\n",
        "        'bloom', 'petals', 'garden', 'meadow', 'river', 'stream', 'valley',\n",
        "        'dawn', 'dusk', 'twilight', 'sunset', 'sunrise', 'nature', 'wild',\n",
        "        'breeze', 'seasons', 'spring', 'autumn', 'winter', 'summer'\n",
        "    ],\n",
        "\n",
        "    'melancholy': [\n",
        "        'sorrow', 'tears', 'pain', 'sadness', 'lonely', 'alone', 'lost',\n",
        "        'grief', 'melancholy', 'wistful', 'ache', 'longing', 'memories',\n",
        "        'fading', 'distant', 'shadows', 'darkness', 'silence', 'empty',\n",
        "        'broken', 'shattered', 'haunting', 'ghost', 'echo', 'whisper',\n",
        "        'farewell', 'goodbye', 'absent', 'void', 'hollow', 'cold'\n",
        "    ],\n",
        "\n",
        "    'hope': [\n",
        "        'hope', 'dream', 'light', 'bright', 'shine', 'glowing', 'radiant',\n",
        "        'tomorrow', 'future', 'promise', 'faith', 'believe', 'strength',\n",
        "        'courage', 'rise', 'soar', 'freedom', 'wings', 'flight', 'possibilities',\n",
        "        'infinite', 'boundless', 'new', 'beginning', 'dawn', 'rebirth',\n",
        "        'inspiration', 'spirit', 'uplift', 'victory', 'triumph', 'joy'\n",
        "    ],\n",
        "\n",
        "    'mystical': [\n",
        "        'magic', 'mystery', 'ethereal', 'celestial', 'cosmic', 'universe',\n",
        "        'infinite', 'eternal', 'transcendent', 'divine', 'sacred', 'mystical',\n",
        "        'enchanted', 'spell', 'wonder', 'awe', 'miracle', 'vision', 'dream',\n",
        "        'spirit', 'phantom', 'shimmer', 'glow', 'mist', 'veil', 'portal',\n",
        "        'realm', 'dimension', 'destiny', 'fate', 'prophecy', 'ancient'\n",
        "    ],\n",
        "\n",
        "    'passion': [\n",
        "        'fire', 'flame', 'burning', 'desire', 'intense', 'fierce', 'wild',\n",
        "        'untamed', 'powerful', 'strong', 'bold', 'daring', 'fearless',\n",
        "        'thunder', 'lightning', 'storm', 'tempest', 'rage', 'fury',\n",
        "        'ardent', 'fervent', 'zealous', 'vivid', 'brilliant', 'electric',\n",
        "        'explosive', 'dynamic', 'energy', 'force', 'magnetism', 'allure'\n",
        "    ]\n",
        "}\n",
        "\n",
        "def get_bow_indices(words: List[str], tokenizer) -> List[int]:\n",
        "    \"\"\"Enhanced tokenization for poetry words\"\"\"\n",
        "    bow_indices = set()\n",
        "    for word in words:\n",
        "        variations = [\n",
        "            word, word.capitalize(), word.upper(),\n",
        "            f\" {word}\", f\" {word.capitalize()}\",\n",
        "            f\"{word}s\", f\" {word}s\",  # plurals\n",
        "            f\"{word}ing\", f\" {word}ing\",  # gerunds\n",
        "            f\"{word}ed\", f\" {word}ed\"  # past tense\n",
        "        ]\n",
        "        for variant in variations:\n",
        "            tokens = tokenizer.encode(variant, add_special_tokens=False)\n",
        "            bow_indices.update(tokens)\n",
        "    return list(bow_indices)\n",
        "\n",
        "bow_dict = {theme: get_bow_indices(words, tokenizer) for theme, words in POETRY_THEMES.items()}\n",
        "\n",
        "print(f\"‚úì Created {len(POETRY_THEMES)} poetic themes\")\n",
        "for theme in POETRY_THEMES:\n",
        "    print(f\"  ‚Ä¢ {theme}: {len(bow_dict[theme])} tokens\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cDTMZMlC_nc",
        "outputId": "ca2549b5-b573-4098-dd9e-40158ddd77c8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defining Poetic Themes...\n",
            "‚úì Created 6 poetic themes\n",
            "  ‚Ä¢ love: 311 tokens\n",
            "  ‚Ä¢ nature: 337 tokens\n",
            "  ‚Ä¢ melancholy: 295 tokens\n",
            "  ‚Ä¢ hope: 319 tokens\n",
            "  ‚Ä¢ mystical: 334 tokens\n",
            "  ‚Ä¢ passion: 293 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SECTION 4: POETRY-OPTIMIZED PPLM\n",
        "\n",
        "print(\"Defining Poetry-Optimized PPLM...\")\n",
        "\n",
        "def compute_bow_loss(logits, bow_indices, device):\n",
        "    \"\"\"Compute BoW loss for poetry generation\"\"\"\n",
        "    probs = F.softmax(logits, dim=-1)\n",
        "    bow_probs = torch.zeros(1).to(device)\n",
        "\n",
        "    for idx in bow_indices:\n",
        "        if idx < probs.shape[-1]:\n",
        "            bow_probs += probs[0, idx]\n",
        "\n",
        "    loss = -torch.log(bow_probs + 1e-8)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def generate_poetry_with_pplm(\n",
        "    prompt: str,\n",
        "    theme: str,\n",
        "    max_length: int = 80,\n",
        "    num_iterations: int = 15,\n",
        "    step_size: float = 0.08,\n",
        "    temperature: float = 0.9,\n",
        "    top_k: int = 100,\n",
        "    top_p: float = 0.95,\n",
        "    repetition_penalty: float = 1.3,\n",
        "    kl_scale: float = 0.005,\n",
        "    gm_scale: float = 0.98\n",
        "):\n",
        "    \"\"\"\n",
        "    Generate poetry with thematic control\n",
        "\n",
        "    Optimized parameters for creative, poetic generation\n",
        "    \"\"\"\n",
        "    if theme not in bow_dict:\n",
        "        print(f\"‚ö† Theme '{theme}' not found. Using 'love'.\")\n",
        "        theme = 'love'\n",
        "\n",
        "    bow_indices = bow_dict[theme]\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
        "    generated = input_ids.clone()\n",
        "\n",
        "    past_key_values = None\n",
        "    generated_tokens = set()\n",
        "\n",
        "    for step in range(max_length):\n",
        "        # Get original logits\n",
        "        with torch.no_grad():\n",
        "            if past_key_values is None:\n",
        "                outputs = model(generated)\n",
        "                past_key_values = outputs.past_key_values\n",
        "                original_logits = outputs.logits[:, -1, :]\n",
        "            else:\n",
        "                outputs = model(generated[:, -1:], past_key_values=past_key_values)\n",
        "                past_key_values = outputs.past_key_values\n",
        "                original_logits = outputs.logits[:, -1, :]\n",
        "\n",
        "        original_probs = F.softmax(original_logits, dim=-1)\n",
        "        perturbed_logits = original_logits.clone()\n",
        "\n",
        "        # Iterative refinement for thematic control\n",
        "        for iteration in range(num_iterations):\n",
        "            current_logits = perturbed_logits.clone().detach().requires_grad_(True)\n",
        "\n",
        "            # BoW loss\n",
        "            bow_loss = compute_bow_loss(current_logits, bow_indices, device)\n",
        "\n",
        "            # KL divergence (very small for more creative freedom)\n",
        "            current_probs = F.softmax(current_logits, dim=-1)\n",
        "            kl_loss = F.kl_div(\n",
        "                F.log_softmax(current_logits, dim=-1),\n",
        "                original_probs,\n",
        "                reduction='batchmean'\n",
        "            )\n",
        "\n",
        "            total_loss = bow_loss + kl_scale * kl_loss\n",
        "            total_loss.backward()\n",
        "\n",
        "            if current_logits.grad is not None:\n",
        "                grad = current_logits.grad\n",
        "                grad_norm = torch.norm(grad)\n",
        "\n",
        "                if grad_norm > 0:\n",
        "                    normalized_grad = grad / grad_norm\n",
        "                    perturbed_logits = perturbed_logits - step_size * normalized_grad\n",
        "\n",
        "        # Geometric fusion\n",
        "        perturbed_probs = F.softmax(perturbed_logits, dim=-1)\n",
        "        fused_probs = (perturbed_probs ** gm_scale) * (original_probs ** (1 - gm_scale))\n",
        "        fused_probs = fused_probs / fused_probs.sum(dim=-1, keepdim=True)\n",
        "        fused_logits = torch.log(fused_probs + 1e-10)\n",
        "\n",
        "        # Apply repetition penalty\n",
        "        for token_id in generated_tokens:\n",
        "            if token_id < fused_logits.shape[-1]:\n",
        "                fused_logits[0, token_id] /= repetition_penalty\n",
        "\n",
        "        # Temperature\n",
        "        fused_logits = fused_logits / temperature\n",
        "\n",
        "        # Top-k\n",
        "        if top_k > 0:\n",
        "            indices_to_remove = fused_logits < torch.topk(fused_logits, top_k)[0][..., -1, None]\n",
        "            fused_logits[indices_to_remove] = float('-inf')\n",
        "\n",
        "        # Top-p (nucleus sampling)\n",
        "        if top_p < 1.0:\n",
        "            sorted_logits, sorted_indices = torch.sort(fused_logits, descending=True)\n",
        "            cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "            sorted_indices_to_remove = cumulative_probs > top_p\n",
        "            sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
        "            sorted_indices_to_remove[..., 0] = 0\n",
        "            indices_to_remove = sorted_indices_to_remove.scatter(1, sorted_indices, sorted_indices_to_remove)\n",
        "            fused_logits[indices_to_remove] = float('-inf')\n",
        "\n",
        "        # Sample\n",
        "        probs = F.softmax(fused_logits, dim=-1)\n",
        "        next_token = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "        generated_tokens.add(next_token.item())\n",
        "        generated = torch.cat([generated, next_token], dim=1)\n",
        "\n",
        "        if next_token.item() == tokenizer.eos_token_id:\n",
        "            break\n",
        "\n",
        "    return tokenizer.decode(generated[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "def generate_baseline_poetry(prompt: str, max_length: int = 80):\n",
        "    \"\"\"Baseline generation for comparison\"\"\"\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            input_ids,\n",
        "            max_length=len(input_ids[0]) + max_length,\n",
        "            temperature=0.9,\n",
        "            top_k=100,\n",
        "            top_p=0.95,\n",
        "            do_sample=True,\n",
        "            repetition_penalty=1.3,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "def format_as_poem(text: str, line_length: int = 60) -> str:\n",
        "    \"\"\"Format generated text as poetry with line breaks\"\"\"\n",
        "    import re\n",
        "\n",
        "    # Split by punctuation and natural breaks\n",
        "    sentences = re.split(r'[.!?,;]', text)\n",
        "    lines = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        sentence = sentence.strip()\n",
        "        if not sentence:\n",
        "            continue\n",
        "\n",
        "        # Split long sentences\n",
        "        words = sentence.split()\n",
        "        current_line = []\n",
        "        current_length = 0\n",
        "\n",
        "        for word in words:\n",
        "            if current_length + len(word) + 1 > line_length and current_line:\n",
        "                lines.append(' '.join(current_line))\n",
        "                current_line = [word]\n",
        "                current_length = len(word)\n",
        "            else:\n",
        "                current_line.append(word)\n",
        "                current_length += len(word) + 1\n",
        "\n",
        "        if current_line:\n",
        "            lines.append(' '.join(current_line))\n",
        "\n",
        "    return '\\n'.join(lines)\n",
        "\n",
        "print(\"‚úì Poetry-optimized functions ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hUxWEA1DKiC",
        "outputId": "69619ab5-e4ca-49e6-ca29-c9a7da0ce501"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defining Poetry-Optimized PPLM...\n",
            "‚úì Poetry-optimized functions ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SECTION 5: POETRY DEMONSTRATIONS\n",
        "\n",
        "print(\"GENERATING POETRY SAMPLES\")\n",
        "\n",
        "\n",
        "# Poetic prompts\n",
        "poetic_prompts = [\n",
        "    \"In the garden of dreams\",\n",
        "    \"Beneath the silver moon\",\n",
        "    \"When shadows fall\",\n",
        "    \"Through the mist of time\"\n",
        "]\n",
        "\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"Demonstration: Poetry with Different Themes\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "for prompt in poetic_prompts[:2]:\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"üìù Prompt: '{prompt}'\")\n",
        "    print('='*70)\n",
        "\n",
        "    # Show 3 themes\n",
        "    for theme in ['love', 'nature', 'melancholy']:\n",
        "        print(f\"\\nüé≠ Theme: [{theme.upper()}]\")\n",
        "        print(\"-+=+-\" * 10)\n",
        "        poetry = generate_poetry_with_pplm(\n",
        "            prompt,\n",
        "            theme=theme,\n",
        "            max_length=60,\n",
        "            num_iterations=15,\n",
        "            step_size=0.08\n",
        "        )\n",
        "        formatted = format_as_poem(poetry)\n",
        "        print(formatted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLVjcXtyDavg",
        "outputId": "66cec961-474a-47af-e47d-d0a58f77792b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATING POETRY SAMPLES\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Demonstration: Poetry with Different Themes\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "======================================================================\n",
            "üìù Prompt: 'In the garden of dreams'\n",
            "======================================================================\n",
            "\n",
            "üé≠ Theme: [LOVE]\n",
            "-+=+--+=+--+=+--+=+--+=+--+=+--+=+--+=+--+=+--+=+-\n",
            "In the garden of dreams We played with baby blue flowers\n",
            "You know what you do to me now\n",
            "And now the house's A black meadow And the trees are gray\n",
            "Beware the caribou Where are they\n",
            "Beware of the baby\n",
            "\n",
            "üé≠ Theme: [NATURE]\n",
            "-+=+--+=+--+=+--+=+--+=+--+=+--+=+--+=+--+=+--+=+-\n",
            "In the garden of dreams I think of the trees in our garden\n",
            "of dreams ‚Äî they are in our garden of dreams\n",
            "\" she said\n",
            "\"The trees can breathe\n",
            "They do things\n",
            "They look for the light\n",
            "\" So I took her hands\n",
            "I took them\n",
            "and they smelled of roses\n",
            "I didn\n",
            "\n",
            "üé≠ Theme: [MELANCHOLY]\n",
            "-+=+--+=+--+=+--+=+--+=+--+=+--+=+--+=+--+=+--+=+-\n",
            "In the garden of dreams\n",
            "at midnight we found her\n",
            "She was carrying her own basket\n",
            "full of apples\n",
            "and of apples we are sure\n",
            "and\n",
            "in addition\n",
            "she had basketfuls of apples and pears\n",
            "and other items of good fruit\n",
            "She put the apple on the little plate and and was about\n",
            "\n",
            "======================================================================\n",
            "üìù Prompt: 'Beneath the silver moon'\n",
            "======================================================================\n",
            "\n",
            "üé≠ Theme: [LOVE]\n",
            "-+=+--+=+--+=+--+=+--+=+--+=+--+=+--+=+--+=+--+=+-\n",
            "Beneath the silver moon in the sky in the last days\n",
            "they shall come with the mighty ravens\n",
            "For the Lord says to me to thee\n",
            "and in me to the whole earth\n",
            "It is days of mourning to the saints\n",
            "8\n",
            "\"Now\n",
            "shall one of the mighty ravens to the raven\n",
            "\n",
            "üé≠ Theme: [NATURE]\n",
            "-+=+--+=+--+=+--+=+--+=+--+=+--+=+--+=+--+=+--+=+-\n",
            "Beneath the silver moon the stars were brightening their\n",
            "bright reds\n",
            "turning purple\n",
            "red and purple\n",
            "\" We'll see the same phenomenon in the same spot every\n",
            "night\n",
            "bright red\n",
            "And when we see red\n",
            "we must interpret it in our own way ‚Äî through our\n",
            "perceptions\n",
            "our own vision\n",
            "\n",
            "üé≠ Theme: [MELANCHOLY]\n",
            "-+=+--+=+--+=+--+=+--+=+--+=+--+=+--+=+--+=+--+=+-\n",
            "Beneath the silver moonlight glistened a faint green and\n",
            "yellow glow of power\n",
            "a power of pure power and truth\n",
            "and the power to control the world and shape it for his own\n",
            "advantage\n",
            "\"Moody\n",
            "that wasn't the power of the light\n",
            "That power came from the stone\n",
            "Without\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SECTION 6: THEME ANALYSIS\n",
        "\n",
        "\n",
        "print(\"THEMATIC ANALYSIS\")\n",
        "\n",
        "\n",
        "def analyze_theme(text, theme):\n",
        "    \"\"\"Analyze theme word usage\"\"\"\n",
        "    text_lower = text.lower()\n",
        "    theme_words = POETRY_THEMES[theme]\n",
        "    found = [w for w in theme_words if w in text_lower]\n",
        "    return found\n",
        "\n",
        "prompt = \"The heart remembers\"\n",
        "print(f\"\\nPrompt: '{prompt}'\\n\")\n",
        "\n",
        "for theme in ['love', 'melancholy', 'hope']:\n",
        "    poetry = generate_poetry_with_pplm(prompt, theme, max_length=50)\n",
        "    found = analyze_theme(poetry, theme)\n",
        "    print(f\"\\n{theme.upper()}:\")\n",
        "    print(f\"  {poetry}\")\n",
        "    print(f\"  ‚úì Theme words: {', '.join(found[:8])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYYqKUaqDlFJ",
        "outputId": "da45600e-5745-472b-8523-1e9f32166d36"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THEMATIC ANALYSIS\n",
            "\n",
            "Prompt: 'The heart remembers'\n",
            "\n",
            "\n",
            "LOVE:\n",
            "  The heart remembers when the heart is dead.\n",
            "\n",
            "Now there's no heart after all, just dead. You know that.\n",
            "\n",
            "When you want to make progress in your dead heart's life,\n",
            "\n",
            "Just keep in mind that it doesn't have the\n",
            "  ‚úì Theme words: heart\n",
            "\n",
            "MELANCHOLY:\n",
            "  The heart remembers as though it had been torn, and it beats without a memory, but sometimes a terrible pain and a terrible sight are so close to your consciousness so that you cannot bear them. Many times are you afraid and think you are going crazy or a crazy\n",
            "  ‚úì Theme words: pain\n",
            "\n",
            "HOPE:\n",
            "  The heart remembers no names. It is a strange child. Some say it is a boy, some say it is an elf, and some, like the ones at home and at school, say the same thing. Every child wants its name. The heart is not\n",
            "  ‚úì Theme words: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SECTION 7: INTERACTIVE POETRY GENERATOR\n",
        "\n",
        "print(\"INTERACTIVE POETRY GENERATOR\")\n",
        "\n",
        "def interactive_poetry():\n",
        "    \"\"\"Interactive poetry generation\"\"\"\n",
        "    print(\"\\nüé® Create Your Poem!\")\n",
        "    print(f\"Available themes: {', '.join(POETRY_THEMES.keys())}\")\n",
        "\n",
        "    try:\n",
        "        prompt = input(\"\\nüìù Enter your opening line: \").strip()\n",
        "        if not prompt:\n",
        "            prompt = \"In the silence of night\"\n",
        "            print(f\"Using default: '{prompt}'\")\n",
        "\n",
        "        theme = input(f\"üé≠ Choose theme ({'/'.join(list(POETRY_THEMES.keys())[:3])}...): \").lower().strip()\n",
        "        if theme not in POETRY_THEMES:\n",
        "            theme = 'love'\n",
        "            print(f\"Using '{theme}' theme\")\n",
        "\n",
        "        length = input(\"üìè Length (short/medium/long) [medium]: \").lower().strip()\n",
        "        max_len = {'short': 40, 'medium': 60, 'long': 100}.get(length, 60)\n",
        "\n",
        "        print(f\"\\n‚ú® Generating {theme} poetry...\")\n",
        "        print(f\"   Prompt: '{prompt}'\")\n",
        "        print(f\"   Length: {length}\")\n",
        "\n",
        "        # Generate\n",
        "        poetry = generate_poetry_with_pplm(\n",
        "            prompt,\n",
        "            theme=theme,\n",
        "            max_length=max_len,\n",
        "            num_iterations=15,\n",
        "            step_size=0.08\n",
        "        )\n",
        "\n",
        "        # Format and display\n",
        "        formatted = format_as_poem(poetry)\n",
        "        print(f\"\\n{formatted}\\n\")\n",
        "\n",
        "        # Analysis\n",
        "        found = analyze_theme(poetry, theme)\n",
        "        print(f\"üìä Analysis:\")\n",
        "        print(f\"   Theme: {theme}\")\n",
        "        print(f\"   Words: {len(poetry.split())} words\")\n",
        "        print(f\"   Theme words used: {', '.join(found[:10])}\")\n",
        "\n",
        "        # Offer different theme\n",
        "        print(\"\\n\" + \"-\"*70)\n",
        "        print(\"üîÑ Same prompt, different theme:\")\n",
        "        alt_theme = input(f\"Try another theme ({'/'.join([t for t in POETRY_THEMES.keys() if t != theme][:3])}): \").strip()\n",
        "\n",
        "        if alt_theme in POETRY_THEMES:\n",
        "            print(f\"\\n‚ú® Generating {alt_theme} version...\")\n",
        "            alt_poetry = generate_poetry_with_pplm(prompt, alt_theme, max_length=max_len)\n",
        "            alt_formatted = format_as_poem(alt_poetry)\n",
        "            print(f\"\\n{alt_formatted}\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "# Run interactive demo\n",
        "interactive_poetry()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTxsIA9eD1hR",
        "outputId": "df43f1f5-ad87-4218-ade0-0a8ba63061a0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INTERACTIVE POETRY GENERATOR\n",
            "\n",
            "üé® Create Your Poem!\n",
            "Available themes: love, nature, melancholy, hope, mystical, passion\n",
            "\n",
            "‚ú® Generating hope poetry...\n",
            "   Prompt: 'the sky is sweer looking today'\n",
            "   Length: medium\n",
            "\n",
            "the sky is sweer looking today than the moon and even the\n",
            "stars have turned to dust\n",
            "The dust is no longer there\n",
            "I am now looking north up to the mountains to the South\n",
            "I now have to walk up to a cloud and the clouds and I don't\n",
            "even know what clouds are or where I'm going\n",
            "\n",
            "üìä Analysis:\n",
            "   Theme: hope\n",
            "   Words: 59 words\n",
            "   Theme words used: \n",
            "\n",
            "----------------------------------------------------------------------\n",
            "üîÑ Same prompt, different theme:\n",
            "Try another theme (love/nature/melancholy): melancholy\n",
            "\n",
            "‚ú® Generating melancholy version...\n",
            "\n",
            "the sky is sweer looking today (sorry)\n",
            "I'll just get out of here and see if I get another chance\n",
            "\" She looked over at him\n",
            "\"Good luck\n",
            "\" He glanced back at the snow and grinned\n",
            "\"See ya at the snow race\n",
            "I'll be there too\n",
            "too\n",
            "\" \"Thanks\n",
            "\" he replied as he\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example showcase\n",
        "\n",
        "print(\"üåü EXAMPLE SHOWCASE\")\n",
        "\n",
        "\n",
        "examples = [\n",
        "    (\"Love\", \"Two hearts\"),\n",
        "    (\"Nature\", \"The mountain stands\"),\n",
        "    (\"Mystical\", \"In the realm of dreams\")\n",
        "]\n",
        "\n",
        "for theme, prompt in examples:\n",
        "    print(f\"\\n{theme.upper()}: '{prompt}'\")\n",
        "    poetry = generate_poetry_with_pplm(prompt, theme.lower(), max_length=45)\n",
        "    print(format_as_poem(poetry))\n",
        "\n",
        "print(\"‚úÖ POETRY GENERATOR READY!\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"üé≠üé≠üé≠üé≠üé≠üé≠üé≠üé≠üé≠üé≠üé≠üé≠üé≠üé≠üé≠üé≠üé≠üé≠üé≠üé≠üé≠\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HZKdsTl0NRx",
        "outputId": "97581be5-6d7f-4300-b3cc-21fedebf521b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåü EXAMPLE SHOWCASE\n",
            "\n",
            "LOVE: 'Two hearts'\n",
            "Two hearts\n",
            "One big heart\n",
            "\" they all chanted together\n",
            "\"Do you even remember your family\n",
            "you\n",
            "or even the blood or how they died\n",
            "\" the blooded soldiers asked in a bitter tone\n",
            "They stood\n",
            "facing\n",
            "\n",
            "NATURE: 'The mountain stands'\n",
            "The mountain stands in a valley that's covered in snow\n",
            "a stark contrast with the lush green of this remote coastal\n",
            "paradise\n",
            "In July\n",
            "the snow melted\n",
            "allowing the mountain to rise in elevation to the heights\n",
            "of 1530 m\n",
            "\n",
            "MYSTICAL: 'In the realm of dreams'\n",
            "In the realm of dreams and imagination\n",
            "she and I have been pretty lucky so far\n",
            "I have loved my first dream\n",
            "I had a dream I had that I would live among people with\n",
            "beautiful hair and that would change my life forever\n",
            "‚úÖ POETRY GENERATOR READY!\n",
            "üé≠üé≠üé≠üé≠üé≠üé≠üé≠üé≠üé≠üé≠üé≠üé≠üé≠üé≠üé≠üé≠üé≠üé≠üé≠üé≠üé≠\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GYC-kS1N2oGu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}